# -*- coding: utf-8 -*-
"""Finance News Analysis_Naive bayes_Data kmrn.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1YEXPeWlwPkvrLPW9Yfozw9gBu_LyVXF5
"""

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

import matplotlib.pyplot as plt
import seaborn as sns

df = pd.read_csv('/content/data.csv', encoding='latin-1', names=['Sentiment', 'Text'])

# Display the DataFrame
df.head()

"""### Data Cleaning"""

import re
def remove_html_tags(text):
    clean_text = re.compile('<.*?>')
    return re.sub(clean_text,'',text)

df['Text'] = df['Text'].apply(remove_html_tags)
df.sample(4)

import nltk
nltk.download('punkt')
nltk.download('stopwords')

from nltk.corpus import stopwords
from nltk.stem import PorterStemmer
from nltk.tokenize import word_tokenize
stopwords_set = set(stopwords.words('english'))
ps = PorterStemmer()

def clean(text):
    words = word_tokenize(text)
    transformed_text = []
    for w in words:
        if w.isalnum():
            transformed_text.append(w.lower())

    cleaned_text = []
    for w in transformed_text:
        stemmed_word = ps.stem(w)
        if stemmed_word not in stopwords_set:
            cleaned_text.append(stemmed_word)

    return ' '.join(cleaned_text)

clean('Kohli was dancing this morning at the stage')

df['Text'] = df['Text'].apply(clean)
df.sample(4)

"""WordCloud"""

!pip install wordcloud

from wordcloud import WordCloud
import matplotlib.pyplot as plt
df['Text'] = df['Text'].astype(str)

wordcloud = WordCloud(width=800, height=400, background_color='white').generate(' '.join(df['Text']))

plt.figure(figsize=(10, 5))
plt.imshow(wordcloud, interpolation='bilinear')
plt.axis('off')
plt.show()

"""### CountVectorizer and LabelEncoder"""

from sklearn.feature_extraction.text import CountVectorizer
from sklearn.preprocessing import LabelEncoder

##label encoder to transform target column
le = LabelEncoder()
trf  = le.fit_transform(df['Sentiment'])
trf = pd.DataFrame(trf)
df['Sentiment'] = trf
df.sample(4)

cv = CountVectorizer(max_features=5000)

df['Text'] = df['Text'].astype(str)
vectors = cv.fit_transform(df['Text'])
vectors.shape

vectors = cv.fit_transform(df['Text'])
vectors.shape

"""### Train Test Splitting"""

from sklearn.model_selection import train_test_split

vectors = vectors.toarray()

X = vectors
y = df['Sentiment']
X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2)
X_train.shape

"""# Model Traning (Naive Bayes)"""

from sklearn.naive_bayes import GaussianNB,MultinomialNB,BernoulliNB
from sklearn.metrics import accuracy_score

gnb = GaussianNB()
mnb = MultinomialNB()
bnb = BernoulliNB()

model = [gnb,mnb,bnb]

for m in model:
    m.fit(X_train,y_train)
    y_preds = m.predict(X_test)
    print(f'{m} Accuracy score is :',accuracy_score(y_test,y_preds))